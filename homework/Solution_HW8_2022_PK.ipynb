{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd47e039",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Mark Hendricks </div>\n",
    "\n",
    "<left>FINM 36700 - Portfolio Theory and Risk Management</left> \n",
    "<br>\n",
    "<left>Fall 2022</left>\n",
    "\n",
    "<h2><center> Homework 8 - Long-Term Capital Management, L.P. </center></h2>\n",
    "\n",
    "<center>Due on Monday, Nov 28</center>\n",
    "\n",
    "<h3><span style=\"color:#00008B\">Solution - Piyush Kontu</span></h3>\n",
    "\n",
    "<h3><span style=\"color:#00008B\">Email - pkontu@uchicago.edu</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f152fb5",
   "metadata": {},
   "source": [
    "### Case: Long-Term Capital Management, L.P. (A) [HBS 9-200-007]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b3d85",
   "metadata": {},
   "source": [
    "## 1)  Conceptual issues for LTCM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae695d2",
   "metadata": {},
   "source": [
    "### 1.1) Describe LTCM's investment strategy with regard to the following aspects:\n",
    "- #### Securities traded\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:**  LTCM tried to trade on market mispricing and arbitrage, Relative Value and Convergence trades. They go long-short on these arbitrages. Use leverage to trade bigger principal on these small mispricings and try to hedge out their positions via their long-short trades.</span>\n",
    "\n",
    "\n",
    "<span style=\"color:#00008B\"> LTCM was also heavily involved income and credit, and they also have sizeable positions in equities. In all these asset classes, they trade a large number of securities, across global markets.</span>\n",
    "\n",
    "\n",
    "- #### Trading frequency\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:**  LTCM's trading frequency varied according to their strategies. Their largest investment in the form of convergence trades had a long term trading horizon and frequency (weeks or months).</span>\n",
    "\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:**  Mostly they are not trying to arbitrage intraday movements and nor odo they make long-term directional bets. </span>\n",
    "\n",
    "- #### Skewness (Do they seek many small wins or a few big hits?)\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:** They seek small positive returns using leverage and do not bet significantly on any specific events. Have lower skewness than SPY. <br> However, they are susceptible to extreme market events.</span>\n",
    "\n",
    "- #### Forecasting (What is behind their selection of trades?)\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:** Build models to find mispricing and the reason behind the mispricing. Then forecast their P&L on these trades. Their forecast is not better because of better mathematical model (the convergence trade/ relative value theory is not the edge), it is their knowledge of the market.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ec9a4",
   "metadata": {},
   "source": [
    "### 1.2) What are LTCM's biggest advantages over its competitors?\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:** <br> <b> 1) Efficient financing:  </b>Their edge was on financing and funding, along with their proprietary trading and modelling capabilities.<br> <b>2)  Fund Size:  </b>They had a larger AUM, meaning they could lever at favorable rates <br> <b>3) Collatralization:</b> Better collatralize these positions. (pay lower haircuts) <br> <b>4) Long-term Horizon:  </b> Long term commitment of capital from investors as well as availability of credit line <br> <b>5) Liquidity and Hedging:</b> LTCM has in place many mechanisms to ensure liquidity. They also avoid taking too much default risk or explicit directional bets.  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2f1f5",
   "metadata": {},
   "source": [
    "### 1.3) The case discusses four types of funding risk facing LTCM:\n",
    "\n",
    "### The case discusses specific ways in which LTCM manages each of these risks. Briefly discuss them.\n",
    "\n",
    "- #### collateral haircuts\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:** The haircuts go up in a market disruption event leading to unfavorable collateral terms for LTCM in terms of funding a spread trade </span>\n",
    "\n",
    "<span style=\"color:#00008B\">For most trades, LTCM obtains 100% financing on a fully collateralized basis. Furthermore, LTCM stress tests the haircuts across its asset classes.</span>\n",
    "\n",
    "- #### repo maturity\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:** In an adverse situation, where their credit risk goes up, they wont be able to secure these longer term repos which were favorable to their trades. </span>\n",
    "\n",
    "<span style=\"color:#00008B\"> LTCM goes against the norm by entering into relatively long-maturity repo. While much of it is overnight, LTCM uses contracts that typically have maturity of 6-12 months. Furthermore, LTCM manages their aggregate repo maturity. </span>\n",
    "\n",
    "- #### equity redemption\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:** If in a convergence trade, the two securities, before converging, diverge a lot, LTCM are facing redemption risk from their investors at a time where the Margin calls need them to furhter finance their strategies.<br><br> Equity Redemption at a unfavorable time also leads LTCM to unwind their positions at unfavorable rates leading to further losses of capital. </span>\n",
    "\n",
    "<span style=\"color:#00008B\">  The firm is highly levered, so equity funding risk is especially important. LTCM restricts redemptions of equity year by year. The restriction is particularly strong in that unredeemed money is re-locked. </span>\n",
    "\n",
    "\n",
    "- #### loan access\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:**  Loan access can be tough to come by in times of a crisis, leading to a further decline in the fund's performance.</span>\n",
    "\n",
    "<span style=\"color:#00008B\">  For debt funding, LTCM negotiated a revolving loan that has no Material Adverse Change clause. Thus, the availability of debt funding is not so highly correlated with fund performance. </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98701998",
   "metadata": {},
   "source": [
    "### 1.4) LTCM is largely in the business of selling liquidity and volatility. Describe how LTCM accounts for liquidity risk in their quantitative measurements.\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:**  LTCM required counterparties to maitain the collateral balance via a 'two-way mark to market process on a daily basis. Thus the cash flow coming in from the counterparties mark to market would fund LTCM's outflow for the mark to market call on their offsetting position.</span>\n",
    "\n",
    "<span style=\"color:#00008B\">LTCM als also estimated theoretical worst case haircuts it would face in adverse market situations. Forecasting these worst case liquidity LTCM was able to better structure its financing so as not to liquidate its positions solely due to these adverse market events.</span>\n",
    "\n",
    "<span style=\"color:#00008B\">LTCM attempts to account for liquidity risk quantitatively by adjusting security correlations. For short-term horizons, LTCM assumes positive correlation between all trade cat- egories. Even if their net exposure to a strategy flips sides, they still assume positive correlation to the new net position</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ab795",
   "metadata": {},
   "source": [
    "### 1.5) Is leverage risk currently a concern for LTCM?\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:**  Currently since there were no extreme market events, leverage risk is not a concern, but still a potential threat for LTCM. Given the size of their commited capital and fewer opportunites for the excess capital to enhance LTCM's return, they are considering returning some of the investments made, which would reduce the leverage.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eba8e3",
   "metadata": {},
   "source": [
    "### 1.6) Many strategies of LTCM rely on converging spreads. LTCM feels that these are almost win/win situations because of the fact that if the spread converges, they make money. If it diverges, the trade becomes even more attractive, as convergence is still expected at a future date. <br> <br> What is the risk in these convergence trades?\n",
    "\n",
    "<span style=\"color:#00008B\"> **Solution:**  About a year after the time of the case, the fund loses most of its value due to non-converging trades. So clearly there is some risk! </span>\n",
    "\n",
    "<span style=\"color:#00008B\">Positions are subject to liquidity risk. If market liquidity dries up or the markets become segmented, the divergent spreads can persist for a long time. This indeed happens later to LTCM. The trades that get them in trouble ultimately pay off, but not before LTCM blows up. LTCM believes it can exit these convergence trades if they become too unprofitable. However, a stop-loss order is not the same as a put option. If the price jumps discontinuously through the stop-loss, then it is ineffective.</span>\n",
    "\n",
    "<span style=\"color:#00008B\">Or a market may be paralyzed/illiquid when trying to execute the stop-loss. A put option does not need to worry about price impact, whereas a stop-loss does. Finally, a stop-loss ensures that an investor sells as soon as a security price hits a worst-case scenario, ensuring unfavorable market timing.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4501dc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f5d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[15, 6]\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1b701",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0503014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_summary(return_data):\n",
    "    \"\"\" \n",
    "        Returns the Performance Stats for given set of returns\n",
    "        Inputs: \n",
    "            return_data - DataFrame with Date index and Monthly Returns for different assets/strategies.\n",
    "        Output:\n",
    "            summary_stats - DataFrame with annualized mean return, vol, sharpe ratio. Skewness, Excess Kurtosis, Var (0.5) and\n",
    "                            CVaR (0.5) and drawdown based on monthly returns. \n",
    "    \"\"\"\n",
    "    summary_stats = return_data.mean().to_frame('Mean').apply(lambda x: x*12)\n",
    "    summary_stats['Volatility'] = return_data.std().apply(lambda x: x*np.sqrt(12))\n",
    "    summary_stats['Sharpe Ratio'] = summary_stats['Mean']/summary_stats['Volatility']\n",
    "    \n",
    "    summary_stats['Skewness'] = return_data.skew()\n",
    "    summary_stats['Excess Kurtosis'] = return_data.kurtosis()\n",
    "    summary_stats['VaR (0.5)'] = return_data.quantile(.05, axis = 0)\n",
    "    summary_stats['CVaR (0.5)'] = return_data[return_data <= return_data.quantile(.05, axis = 0)].mean()\n",
    "    summary_stats['Min'] = return_data.min()\n",
    "    summary_stats['Max'] = return_data.max()\n",
    "    \n",
    "    wealth_index = 1000*(1+return_data).cumprod()\n",
    "    previous_peaks = wealth_index.cummax()\n",
    "    drawdowns = (wealth_index - previous_peaks)/previous_peaks\n",
    "\n",
    "    summary_stats['Max Drawdown'] = drawdowns.min()\n",
    "    summary_stats['Peak'] = [previous_peaks[col][:drawdowns[col].idxmin()].idxmax() for col in previous_peaks.columns]\n",
    "    summary_stats['Bottom'] = drawdowns.idxmin()\n",
    "    \n",
    "    recovery_date = []\n",
    "    for col in wealth_index.columns:\n",
    "        prev_max = previous_peaks[col][:drawdowns[col].idxmin()].max()\n",
    "        recovery_wealth = pd.DataFrame([wealth_index[col][drawdowns[col].idxmin():]]).T\n",
    "        recovery_date.append(recovery_wealth[recovery_wealth[col] >= prev_max].index.min())\n",
    "    summary_stats['Recovery'] = recovery_date\n",
    "    \n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee0fc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_based_performance(factor,fund_ret,rf,constant = True):\n",
    "    \"\"\" \n",
    "        Returns the Regression based performance Stats for given set of returns and factors\n",
    "        Inputs:\n",
    "            factor - Dataframe containing monthly returns of the regressors\n",
    "            fund_ret - Dataframe containing monthly excess returns of the regressand fund\n",
    "            rf - Monthly risk free rate of return\n",
    "        Output:\n",
    "            summary_stats - (Beta of regression, treynor ratio, information ratio, alpha). \n",
    "    \"\"\"\n",
    "    if constant:\n",
    "        X = sm.tools.add_constant(factor)\n",
    "    else:\n",
    "        X = factor\n",
    "    y=fund_ret\n",
    "    model = sm.OLS(y,X,missing='drop').fit()\n",
    "    \n",
    "    if constant:\n",
    "        beta = model.params[1:]\n",
    "        alpha = round(float(model.params['const']),6) *12\n",
    "\n",
    "        \n",
    "    else:\n",
    "        beta = model.params\n",
    "    treynor_ratio = ((fund_ret - rf).mean()*12)/beta[0]\n",
    "    tracking_error = (model.resid.std()*np.sqrt(12))\n",
    "    if constant:        \n",
    "        information_ratio = model.params[0]*12/tracking_error\n",
    "    r_squared = model.rsquared\n",
    "    if constant:\n",
    "        return (beta,treynor_ratio,information_ratio,alpha,r_squared,tracking_error,model.resid)\n",
    "    else:\n",
    "        return (beta,treynor_ratio,r_squared,tracking_error,model.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0cb5a",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583663ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fund Capital ($billions)</th>\n",
       "      <th>Gross Monthly Performance</th>\n",
       "      <th>Net Monthly Performance</th>\n",
       "      <th>Index of Net Performance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1994-03-31</th>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-04-30</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-05-31</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.053</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-06-30</th>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-07-31</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.084</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fund Capital ($billions)  Gross Monthly Performance  \\\n",
       "Date                                                              \n",
       "1994-03-31                       1.1                     -0.011   \n",
       "1994-04-30                       1.1                      0.014   \n",
       "1994-05-31                       1.2                      0.068   \n",
       "1994-06-30                       1.2                     -0.039   \n",
       "1994-07-31                       1.4                      0.116   \n",
       "\n",
       "            Net Monthly Performance  Index of Net Performance  \n",
       "Date                                                           \n",
       "1994-03-31                   -0.013                      0.99  \n",
       "1994-04-30                    0.008                      1.00  \n",
       "1994-05-31                    0.053                      1.05  \n",
       "1994-06-30                   -0.029                      1.02  \n",
       "1994-07-31                    0.084                      1.10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltcm_returns = pd.read_excel(r'C:\\Users\\piyus\\Documents\\Repos\\finm-portfolio-2022\\data\\ltcm_exhibits_data.xlsx', header=[2], sheet_name='Exhibit 2')\n",
    "ltcm_returns = ltcm_returns[1:].rename(columns={'Unnamed: 0':'Date'})\n",
    "ltcm_returns = ltcm_returns.set_index('Date')\n",
    "ltcm_returns = ltcm_returns.loc[:,['Fund Capital ($billions)','Gross Monthly Performancea','Net Monthly Performanceb','Index of Net Performance']]\n",
    "ltcm_returns = ltcm_returns[:53].rename(columns={'Gross Monthly Performancea':'Gross Monthly Performance','Net Monthly Performanceb':'Net Monthly Performance'})\n",
    "ltcm_returns.index = pd.to_datetime(ltcm_returns.index) + pd.offsets.MonthEnd(0) \n",
    "ltcm_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b60538b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-03-31</th>\n",
       "      <td>0.044458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-04-30</th>\n",
       "      <td>0.008624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-05-31</th>\n",
       "      <td>-0.024961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-06-30</th>\n",
       "      <td>0.038341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-07-31</th>\n",
       "      <td>-0.017764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SPY\n",
       "Date                \n",
       "1998-03-31  0.044458\n",
       "1998-04-30  0.008624\n",
       "1998-05-31 -0.024961\n",
       "1998-06-30  0.038341\n",
       "1998-07-31 -0.017764"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmo_total_ret = pd.read_excel(r'C:\\Users\\piyus\\Documents\\Repos\\finm-portfolio-2022\\data\\gmo_analysis_data.xlsx',sheet_name = 'returns (total)',index_col = 0)\n",
    "gmo_total_ret.index.name = 'Date'\n",
    "spy_total_ret = gmo_total_ret.loc[:,['SPY']]\n",
    "\n",
    "rf = pd.read_excel(r'C:\\Users\\piyus\\Documents\\Repos\\finm-portfolio-2022\\data\\gmo_analysis_data.xlsx',sheet_name = 'risk-free rate',index_col = 0)\n",
    "rf.index.name = 'Date'\n",
    "\n",
    "spy_excess_ret = spy_total_ret.copy()\n",
    "for col in spy_excess_ret.columns:\n",
    "    spy_excess_ret[col] = spy_excess_ret[col] - rf['US3M']\n",
    "\n",
    "ltcm_returns['Net Excess Returns'] = ltcm_returns['Net Monthly Performance'] - rf['US3M']\n",
    "ltcm_returns['Gross Excess Returns'] = ltcm_returns['Gross Monthly Performance'] - rf['US3M']\n",
    "\n",
    "spy_er_ltcm = spy_excess_ret[ltcm_returns.index[0]:ltcm_returns.index[-1]]\n",
    "spy_er_ltcm.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f54d4",
   "metadata": {},
   "source": [
    "## 2) LTCM Risk Decomposition\n",
    "\n",
    "- <h4> On Canvas, find the data file, <code>ltcm exhibits data.xlsx</code>. Get the gross and net (total) returns of LTCM from \"Exhibit 2\".</h4> <br>\n",
    "- <h4>  Get the returns on SPY as well as the risk-free rate from the file, <code>gmo analysis data</code>.</h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4d099",
   "metadata": {},
   "source": [
    "### 2.1) Summary stats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c25704",
   "metadata": {},
   "source": [
    "### 2.1.a) For both the gross and net series of LTCM excess returns, report the mean, volatility, and Sharpe ratios. (Annualize them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20535140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gross Excess Returns</th>\n",
       "      <td>0.242077</td>\n",
       "      <td>0.136232</td>\n",
       "      <td>1.776946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Excess Returns</th>\n",
       "      <td>0.155360</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>1.390059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Mean  Volatility  Sharpe Ratio\n",
       "Gross Excess Returns  0.242077    0.136232      1.776946\n",
       "Net Excess Returns    0.155360    0.111765      1.390059"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltcm_summary = performance_summary(ltcm_returns.loc[:,['Gross Excess Returns','Net Excess Returns']])\n",
    "ltcm_summary.loc[:,['Mean','Volatility','Sharpe Ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794a2e4",
   "metadata": {},
   "source": [
    "### 2.1.b) Report the skewness, kurtosis, and (historic) VaR(.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01ceefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "      <th>VaR (0.5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gross Excess Returns</th>\n",
       "      <td>-0.287725</td>\n",
       "      <td>1.586625</td>\n",
       "      <td>-0.030445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Excess Returns</th>\n",
       "      <td>-0.810239</td>\n",
       "      <td>2.926921</td>\n",
       "      <td>-0.026415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Skewness  Excess Kurtosis  VaR (0.5)\n",
       "Gross Excess Returns -0.287725         1.586625  -0.030445\n",
       "Net Excess Returns   -0.810239         2.926921  -0.026415"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltcm_summary.loc[:,['Skewness','Excess Kurtosis','VaR (0.5)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d82688",
   "metadata": {},
   "source": [
    "### 2.1.c) Comment on how these stats compare to SPY and other assets we have seen. How much do they differ between gross and net?\n",
    "\n",
    "Comparing the Net Monthly Performance of LTCM and Excess returns of SPY, LTCM displays a higher return, with a very similar volatility to SPY. Thus the sharpe ratio of LTCM net of fee and other charges is slightly higher than SPY's. \n",
    "\n",
    "The excess net returns of LTCM however, underperform SPY with similar volatility levels and thus have a slightly lower sharpe ratio.\n",
    "\n",
    "However, looking at other moments, LTCM Net returns are more negatively skewed and have a significantly fatter tail compared to SPY, indicating the presence of heavy negative monthly returns over the sample period. Although, since the VaR of LTCM is lower compared to SPY, the indication is that these negative returns are fewer in frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8b5fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "      <th>VaR (0.5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>0.173823</td>\n",
       "      <td>0.112294</td>\n",
       "      <td>1.547923</td>\n",
       "      <td>-0.433516</td>\n",
       "      <td>-0.362022</td>\n",
       "      <td>-0.04636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean  Volatility  Sharpe Ratio  Skewness  Excess Kurtosis  VaR (0.5)\n",
       "SPY  0.173823    0.112294      1.547923 -0.433516        -0.362022   -0.04636"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_er_summary = performance_summary(spy_er_ltcm)\n",
    "spy_er_summary.loc[:,['Mean','Volatility','Sharpe Ratio','Skewness','Excess Kurtosis','VaR (0.5)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42bbc44",
   "metadata": {},
   "source": [
    "### 2.2) Using the series of net LTCM excess returns, denoted $\\tilde{r}^{LTCM}$, estimate the following regression: <br>\n",
    "\n",
    "### \\begin{align}\n",
    "\\tilde{r}^{LTCM} = \\alpha + \\beta^{m}\\tilde{r}^{m}_{t} +\\epsilon_t\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12573c1e",
   "metadata": {},
   "source": [
    "### 2.2.a) Report  $\\alpha$ and $\\beta^{m}$. Report the $R^{2}$ stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d436dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Market Beta</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>Treynor Ratio</th>\n",
       "      <th>Information Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gross Excess Returns</th>\n",
       "      <td>0.210816</td>\n",
       "      <td>0.179845</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>1.346034</td>\n",
       "      <td>1.564766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Excess Returns</th>\n",
       "      <td>0.131532</td>\n",
       "      <td>0.137114</td>\n",
       "      <td>0.018979</td>\n",
       "      <td>1.133077</td>\n",
       "      <td>1.188141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Alpha  Market Beta  R-Squared  Treynor Ratio  \\\n",
       "Gross Excess Returns  0.210816     0.179845   0.021976       1.346034   \n",
       "Net Excess Returns    0.131532     0.137114   0.018979       1.133077   \n",
       "\n",
       "                      Information Ratio  \n",
       "Gross Excess Returns           1.564766  \n",
       "Net Excess Returns             1.188141  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor = spy_er_ltcm['SPY']\n",
    "reg_sum = []\n",
    "for rets in ['Gross Excess Returns','Net Excess Returns']:\n",
    "    fund_ret = ltcm_returns.loc[:,[rets]]\n",
    "    reg = regression_based_performance(factor,fund_ret,0)\n",
    "    beta_mkt = reg[0][0]\n",
    "    treynor_ratio = reg[1][0]\n",
    "    information_ratio = reg[2]\n",
    "    alpha = reg[3]\n",
    "    r_squared = reg[4]\n",
    "    reg_sum.append(pd.DataFrame([[alpha,beta_mkt,r_squared,treynor_ratio,information_ratio]],columns=['Alpha','Market Beta','R-Squared','Treynor Ratio','Information Ratio'],index = [rets]))\n",
    "\n",
    "mkt_reg_sum = pd.concat(reg_sum)\n",
    "mkt_reg_sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83de47",
   "metadata": {},
   "source": [
    "### 2.2.b) From this regression, does LTCM appear to be a \"closet indexer\"?\n",
    "\n",
    "The R-Squared and $\\beta$ of this univariate regression is fairly low, indicating very low correlation between LTCM and SPY. Based on this, LTCM does not seem to be a closet indexer.\n",
    "\n",
    "This is due to the fact that most of thier trades are long-short in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ee11c",
   "metadata": {},
   "source": [
    "### 2.2.c) From the regression, does LTCM appear to deliver excess returns beyond the risk premium we expect from market exposure?\n",
    "\n",
    "With a significant higher annualized alpha of ~13.15%, LTCM does deliver excess returns beyond the market risk premium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0cb780",
   "metadata": {},
   "source": [
    "### 2.3) Let's check for non-linear market exposure. Run the following regression on LTCM's net excess returns:<br>\n",
    "\n",
    "<center> $\\tilde{r}^{LTCM} = \\alpha + \\beta_{1}\\tilde{r}^{m}_{t} + \\beta_{2}(\\tilde{r}^{m}_{t})^{2} +\\epsilon_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f23fc",
   "metadata": {},
   "source": [
    "### 2.3.a) Report $\\beta_{1}\\, \\beta_{2}$, and the $R^{2}$ stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4e0360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>SPY Beta</th>\n",
       "      <th>$SPY^{2}$ Beta</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>Treynor Ratio</th>\n",
       "      <th>Information Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gross Excess Returns</th>\n",
       "      <td>0.242388</td>\n",
       "      <td>0.219805</td>\n",
       "      <td>-2.586773</td>\n",
       "      <td>0.028458</td>\n",
       "      <td>1.101330</td>\n",
       "      <td>1.805091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Excess Returns</th>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.166878</td>\n",
       "      <td>-1.926746</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>0.930984</td>\n",
       "      <td>1.404397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Alpha  SPY Beta  $SPY^{2}$ Beta  R-Squared  \\\n",
       "Gross Excess Returns  0.242388  0.219805       -2.586773   0.028458   \n",
       "Net Excess Returns    0.155040  0.166878       -1.926746   0.024321   \n",
       "\n",
       "                      Treynor Ratio  Information Ratio  \n",
       "Gross Excess Returns       1.101330           1.805091  \n",
       "Net Excess Returns         0.930984           1.404397  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_er_ltcm['$SPY^{2}$'] = spy_er_ltcm['SPY']**2\n",
    "factor_squared = spy_er_ltcm.loc[:,['SPY','$SPY^{2}$']]\n",
    "quad_reg_sum = []\n",
    "for rets in ['Gross Excess Returns','Net Excess Returns']:\n",
    "    fund_ret = ltcm_returns.loc[:,[rets]]\n",
    "    reg_squared = regression_based_performance(factor_squared,fund_ret,0)\n",
    "    beta_mkt = reg_squared[0][0]\n",
    "    beta_mkt_squared = reg_squared[0][1]\n",
    "    treynor_ratio = reg_squared[1][0]\n",
    "    information_ratio = reg_squared[2]\n",
    "    alpha = reg_squared[3]\n",
    "    r_squared = reg_squared[4]\n",
    "    quad_reg_sum.append(pd.DataFrame([[alpha,beta_mkt,beta_mkt_squared,r_squared,treynor_ratio,information_ratio]],columns=['Alpha','SPY Beta','$SPY^{2}$ Beta','R-Squared','Treynor Ratio','Information Ratio'],index = [rets]))\n",
    "\n",
    "mkt_quad_reg_sum = pd.concat(quad_reg_sum)\n",
    "mkt_quad_reg_sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc62c47b",
   "metadata": {},
   "source": [
    "### 2.3.b) Does the quadratic market factor do much to increase the overall LTCM variation explained by the market?\n",
    "\n",
    "- The Quadratic Market Factor, does lead to slight improvement in the R-Squared of the regression, but the value still remains fairly low, to indicate any relation between LTCM and the market returns.\n",
    "\n",
    "- The increased R-Squared could also be just a factor of multicolinearity, as the alpha in the regression also increases, meaning there is more unexplained returns on adding the quadratic market factor.\n",
    "\n",
    "- The huge negative beta on $\\text{SPY}^2$ is a feature of the factor. The monthly returns are small, thus the squared returns are even smaller, thus the beta has to be larger in magnitude to fir these small returns properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b9bd5",
   "metadata": {},
   "source": [
    "### 2.3.c) From the regression evidence, does LTCM's market exposure behave as if it is long market options or short market options?\n",
    "\n",
    "Since the beta to $\\text{SPY}^{2}$ returns is negative, LTCM's market exposure behaves as if it were short the market options. The beta to SPY can be interpreted as the delta of the market option and the beta to $\\text{SPY}^{2}$ as the gamma to market options (through taylor expansion of market options). Since the gamma of an option is always positive, LTCM seems to be short the positive gamma or short the market options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e651b",
   "metadata": {},
   "source": [
    "### 2.3.d) Should we describe LTCM as being positively or negatively exposed to market volatility?\n",
    "\n",
    "- For a big monthly return, the negative beta for SPY Squared would lead to heavy underperformance of LTCM returns. Big market movements would lead to big underperformance of LTCM.\n",
    "- Thus, LTCM seems to be taking on a negative exposure to market volatility underperforming big deviations in the market and the performance not being impacted much by small deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065b39f",
   "metadata": {},
   "source": [
    "### 2.4) Let's try to pinpoint the nature of LTCM's nonlinear exposure. Does it come more from exposure to up-markets or down-markets? Run the following regression on LTCM's net excess returns:<br>\n",
    "\n",
    "<center> $\\tilde{r}^{LTCM} = \\alpha + \\beta\\tilde{r}^{m}_{t} + \\beta_{u}max(\\tilde{r}^{m}_{t} - k_{1},0) + + \\beta_{d}max(k_{2} - \\tilde{r}^{m}_{t},0) +\\epsilon_t$ \n",
    "    \n",
    "where $k_{1}$ = .03 and $k_{2}$ = -.03. (This is roughly one standard deviation of $\\tilde{r}^{m}$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8477846",
   "metadata": {},
   "source": [
    "### 2.4.a) Report $\\beta,\\beta_{u}, \\beta_{d}$, and the $R^{2}$ stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3232f5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>SPY Beta</th>\n",
       "      <th>SPY Call Beta</th>\n",
       "      <th>SPY Put Beta</th>\n",
       "      <th>R-Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gross Excess Returns</th>\n",
       "      <td>0.173796</td>\n",
       "      <td>0.608536</td>\n",
       "      <td>-1.03835</td>\n",
       "      <td>1.632452</td>\n",
       "      <td>0.063774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Excess Returns</th>\n",
       "      <td>0.101232</td>\n",
       "      <td>0.466610</td>\n",
       "      <td>-0.78214</td>\n",
       "      <td>1.289575</td>\n",
       "      <td>0.055486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Alpha  SPY Beta  SPY Call Beta  SPY Put Beta  \\\n",
       "Gross Excess Returns  0.173796  0.608536       -1.03835      1.632452   \n",
       "Net Excess Returns    0.101232  0.466610       -0.78214      1.289575   \n",
       "\n",
       "                      R-Squared  \n",
       "Gross Excess Returns   0.063774  \n",
       "Net Excess Returns     0.055486  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_er_ltcm['SPY_call'] = np.where(spy_er_ltcm['SPY'] - 0.03 >= 0, spy_er_ltcm['SPY'] - 0.03,0)\n",
    "spy_er_ltcm['SPY_put'] = np.where(-0.03 - spy_er_ltcm['SPY'] >= 0, -0.03 - spy_er_ltcm['SPY'],0)\n",
    "\n",
    "factor = spy_er_ltcm.loc[:,['SPY','SPY_call','SPY_put']]\n",
    "asym_reg_sum = []\n",
    "for rets in ['Gross Excess Returns','Net Excess Returns']:\n",
    "    fund_ret = ltcm_returns.loc[:,[rets]]\n",
    "    reg = regression_based_performance(factor,fund_ret,0)\n",
    "    beta_mkt = reg[0][0]\n",
    "    beta_mkt_call = reg[0][1]\n",
    "    beta_mkt_put = reg[0][2]\n",
    "    treynor_ratio = reg[1]\n",
    "    information_ratio = reg[2]\n",
    "    alpha = reg[3]\n",
    "    r_squared = reg[4]\n",
    "    asym_reg_sum.append(pd.DataFrame([[alpha,beta_mkt,beta_mkt_call,beta_mkt_put,r_squared]],columns=['Alpha','SPY Beta','SPY Call Beta','SPY Put Beta','R-Squared'],index = [rets]))\n",
    "\n",
    "mkt_asym_reg_sum = pd.concat(asym_reg_sum)\n",
    "mkt_asym_reg_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc1ccf",
   "metadata": {},
   "source": [
    "### 2.4.b) Is LTCM long or short the call-like factor? And the put-like factor?\n",
    "\n",
    "Based on the regression betas, LTCM seem to be short the call-like factor and long the put-like factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511505d",
   "metadata": {},
   "source": [
    "### 2.4.c) Which factor moves LTCM more, the call-like factor, or the put-like factor?\n",
    "\n",
    "Since, the magnitude of the put-like factor is significantly higher than the call-like factor, it would drive much of the movement in LTCM returns.\n",
    "\n",
    "The beta to put-like factor seems to be irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19848043",
   "metadata": {},
   "source": [
    "### 2.4.d) In the previous problem, you commented on whether LTCM is positively or negatively exposed to market volatility. Using this current regression, does this volatility exposure come more from being long the market's upside? Short the market's downside? Something else?\n",
    "\n",
    "Since the LTCM returns seem to be shorting the call-like factor and long on put-like factor, they are negatively exposed to market volatility. The negative exposure comes from both the combination of the short position on call-like and long position on put-like factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5693b",
   "metadata": {},
   "source": [
    "## 3) The FX Carry Trade\n",
    "\n",
    "Find an Excel data file, `fx carry data.xlsx`. The file has two sets of data:\n",
    "- Risk-free rates across 5 currencies, as measured by annualized 3-month LIBOR rates.\n",
    "- Spot FX rates, as direct quotes to the USD. (Note that all currencies are quoted as USD per\n",
    "the foreign currency.)\n",
    "\n",
    "\n",
    "For use in the homework, note the following:\n",
    "- For risk-free rate data, $\\tilde{r}^{f,i}_{t,t+1}$, the rate is known and reported in the data at time t. <b> Namely,\n",
    "any given date t in the data file is reporting both ${S}^{i}_{t}$ and $\\tilde{r}^{f,i}_{t,t+1}$</b> <br>\n",
    "- The theory says to use log risk-free rates. You have the risk-free rate in levels: use the following equation to convert them:<br>\n",
    "#### <center> $\\tilde{r}^{f,i}_{t,t+1} = ln(1+ \\tilde{r}^{f,i}_{t,t+1})$ </center><br>\n",
    "- The theory says to use log spot FX prices. You have the FX prices in levels, so directly take their logarithims:<br>\n",
    "#### <center> ${s}^{i}_{t} = ln({S}^{i}_{t})$ </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3f0f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USD1M</th>\n",
       "      <th>GBP1M</th>\n",
       "      <th>EUR1M</th>\n",
       "      <th>CHF1M</th>\n",
       "      <th>JPY1M</th>\n",
       "      <th>log_USD1M</th>\n",
       "      <th>log_GBP1M</th>\n",
       "      <th>log_EUR1M</th>\n",
       "      <th>log_CHF1M</th>\n",
       "      <th>log_JPY1M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-31</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-02-28</th>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-31</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-04-30</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-05-31</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               USD1M     GBP1M     EUR1M     CHF1M     JPY1M  log_USD1M  \\\n",
       "DATE                                                                      \n",
       "1999-01-31  0.000343  0.000411  0.000217  0.000083  0.000028   0.000343   \n",
       "1999-02-28  0.000345  0.000385  0.000217  0.000086  0.000019   0.000345   \n",
       "1999-03-31  0.000343  0.000369  0.000208  0.000083  0.000012   0.000343   \n",
       "1999-04-30  0.000340  0.000367  0.000178  0.000067  0.000008   0.000340   \n",
       "1999-05-31  0.000343  0.000368  0.000178  0.000069  0.000006   0.000343   \n",
       "\n",
       "            log_GBP1M  log_EUR1M  log_CHF1M  log_JPY1M  \n",
       "DATE                                                    \n",
       "1999-01-31   0.000411   0.000217   0.000083   0.000028  \n",
       "1999-02-28   0.000385   0.000217   0.000086   0.000019  \n",
       "1999-03-31   0.000369   0.000208   0.000083   0.000012  \n",
       "1999-04-30   0.000367   0.000178   0.000067   0.000008  \n",
       "1999-05-31   0.000368   0.000178   0.000069   0.000006  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_free_rates = pd.read_excel(r'C:\\Users\\piyus\\Documents\\Repos\\finm-portfolio-2022\\data\\fx_carry_data.xlsx', sheet_name='risk-free rates')\n",
    "risk_free_rates.index = risk_free_rates['DATE']\n",
    "risk_free_rates = risk_free_rates.drop(['DATE'],axis=1)\n",
    "for col in risk_free_rates.columns:\n",
    "    risk_free_rates[col] = risk_free_rates[col]/12\n",
    "    risk_free_rates['log_'+col] = np.log(1+risk_free_rates[col])\n",
    "\n",
    "risk_free_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3069db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USUK</th>\n",
       "      <th>USEU</th>\n",
       "      <th>USSZ</th>\n",
       "      <th>USJP</th>\n",
       "      <th>log_USUK</th>\n",
       "      <th>log_USEU</th>\n",
       "      <th>log_USSZ</th>\n",
       "      <th>log_USJP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-31</th>\n",
       "      <td>1.6457</td>\n",
       "      <td>1.1371</td>\n",
       "      <td>0.705816</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.498166</td>\n",
       "      <td>0.128481</td>\n",
       "      <td>-0.348401</td>\n",
       "      <td>-4.753590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-02-28</th>\n",
       "      <td>1.6027</td>\n",
       "      <td>1.0995</td>\n",
       "      <td>0.689893</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.471690</td>\n",
       "      <td>0.094856</td>\n",
       "      <td>-0.371219</td>\n",
       "      <td>-4.776599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-31</th>\n",
       "      <td>1.6140</td>\n",
       "      <td>1.0808</td>\n",
       "      <td>0.676819</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>0.478716</td>\n",
       "      <td>0.077702</td>\n",
       "      <td>-0.390351</td>\n",
       "      <td>-4.774322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-04-30</th>\n",
       "      <td>1.6085</td>\n",
       "      <td>1.0564</td>\n",
       "      <td>0.655437</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.475302</td>\n",
       "      <td>0.054867</td>\n",
       "      <td>-0.422453</td>\n",
       "      <td>-4.782730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-05-31</th>\n",
       "      <td>1.6020</td>\n",
       "      <td>1.0422</td>\n",
       "      <td>0.654450</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.471253</td>\n",
       "      <td>0.041334</td>\n",
       "      <td>-0.423960</td>\n",
       "      <td>-4.794798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              USUK    USEU      USSZ      USJP  log_USUK  log_USEU  log_USSZ  \\\n",
       "DATE                                                                           \n",
       "1999-01-31  1.6457  1.1371  0.705816  0.008621  0.498166  0.128481 -0.348401   \n",
       "1999-02-28  1.6027  1.0995  0.689893  0.008425  0.471690  0.094856 -0.371219   \n",
       "1999-03-31  1.6140  1.0808  0.676819  0.008444  0.478716  0.077702 -0.390351   \n",
       "1999-04-30  1.6085  1.0564  0.655437  0.008373  0.475302  0.054867 -0.422453   \n",
       "1999-05-31  1.6020  1.0422  0.654450  0.008273  0.471253  0.041334 -0.423960   \n",
       "\n",
       "            log_USJP  \n",
       "DATE                  \n",
       "1999-01-31 -4.753590  \n",
       "1999-02-28 -4.776599  \n",
       "1999-03-31 -4.774322  \n",
       "1999-04-30 -4.782730  \n",
       "1999-05-31 -4.794798  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_rates = pd.read_excel(r'C:\\Users\\piyus\\Dropbox\\UChicago\\FINM 36700 - Portfolio Theory and Risk Management I\\Week 8 - 2021-11-15\\HW 8 - Due 29th Nov\\fx_carry_data.xlsx', sheet_name='fx rates')\n",
    "fx_rates.index = fx_rates['DATE']\n",
    "fx_rates = fx_rates.drop(['DATE'],axis=1)\n",
    "for col in fx_rates.columns:\n",
    "    fx_rates['log_'+col] = np.log(fx_rates[col])\n",
    "\n",
    "fx_rates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a388c",
   "metadata": {},
   "source": [
    "### 3.1) The Static Carry Trade\n",
    "\n",
    "Define the log return of holding the foreign currency using log values of the risk-free rate and\n",
    "log values of the FX rates:<br>\n",
    "#### <center> ${r}^{i}_{t+1} = {s}^{i}_{t+1} - {s}^{i}_{t} + {r}^{f,i}_{t,t+1} $ </center><br>\n",
    "\n",
    "Then the excess log return relative to USD, is expressed as\n",
    "\n",
    "#### <center> $\\tilde{r}^{i}_{t+1} = {s}^{i}_{t+1} - {s}^{i}_{t} + {r}^{f,i}_{t,t+1} - {r}^{f,$}_{t,t+1} $ </center><br>\n",
    "\n",
    "For each foreign currency, i, calculate the excess log return series, $\\tilde{r}_{t+1}$. Report the following\n",
    "stats, (based on the excess log returns.) Annualize them.\n",
    "- mean\n",
    "- volatility\n",
    "- sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "289e3433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Currency Held</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBP</th>\n",
       "      <td>-0.007720</td>\n",
       "      <td>0.086295</td>\n",
       "      <td>-0.089460</td>\n",
       "      <td>-0.096431</td>\n",
       "      <td>0.088009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EUR</th>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.094457</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>-0.104565</td>\n",
       "      <td>0.092241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHF</th>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.098469</td>\n",
       "      <td>0.181872</td>\n",
       "      <td>-0.118379</td>\n",
       "      <td>0.130775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPY</th>\n",
       "      <td>-0.000764</td>\n",
       "      <td>0.091440</td>\n",
       "      <td>-0.008350</td>\n",
       "      <td>-0.084590</td>\n",
       "      <td>0.074844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Mean  Volatility  Sharpe Ratio       Min       Max\n",
       "Currency Held                                                        \n",
       "GBP           -0.007720    0.086295     -0.089460 -0.096431  0.088009\n",
       "EUR            0.000273    0.094457      0.002889 -0.104565  0.092241\n",
       "CHF            0.017909    0.098469      0.181872 -0.118379  0.130775\n",
       "JPY           -0.000764    0.091440     -0.008350 -0.084590  0.074844"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_spot_map = {'log_GBP1M':'log_USUK'\n",
    "               ,'log_EUR1M':'log_USEU'\n",
    "               ,'log_CHF1M':'log_USSZ'\n",
    "               ,'log_JPY1M':'log_USJP'\n",
    "}\n",
    "\n",
    "fx_hldg_lst = []\n",
    "for k,v in fx_spot_map.items():\n",
    "    fx_hldg_excess_ret = fx_rates[v] - fx_rates[v].shift(1) + risk_free_rates[k].shift(1) - risk_free_rates['log_USD1M'].shift(1)\n",
    "    fx_hldg_summary = performance_summary(fx_hldg_excess_ret.to_frame().dropna())\n",
    "    fx_hldg_summary.index = [k[4:7]]\n",
    "    fx_hldg_summary.index.name = 'Currency Held'\n",
    "    fx_hldg_lst.append(fx_hldg_summary)\n",
    "\n",
    "fx_hldg_perf_summary = pd.concat(fx_hldg_lst)\n",
    "fx_hldg_perf_summary.loc[:,['Mean','Volatility','Sharpe Ratio','Min','Max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9930f",
   "metadata": {},
   "source": [
    "### What differences do you see across currencies?\n",
    "\n",
    "An FX Carry trade on GBP produces mean excess returns for the sample period with a lower volatility. For remaining 3 currencies, we see negative returns and higher volatility and subsequently worsening sharpe ratios.\n",
    "\n",
    "Strengthening of GBP compared to USD during 1994-1997 was a driving factor behind the carry trade in GBP being profitable in USD terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d358b32d",
   "metadata": {},
   "source": [
    "### 3.2) Implications for UIP:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df25e2",
   "metadata": {},
   "source": [
    "### 3.2.a) Do any of these stats contradict the (log version) of Uncovered Interest Parity (UIP)?\n",
    "\n",
    "UIP states that the mean return of these currencies positions should be zero as the change in the spot fx rate is completely explained by the changes in risk free rates. However, none of the mean returns for the currencies are 0. \n",
    "\n",
    "On closer inspection the sharpe ratio of all currencies except JPY seems to be within the 95% confidence interval significance value and thus the mean return stats might not be significantly different from 0.\n",
    "\n",
    "For JPY, on the other hand we see a significant deviation of ~2 standard deviations and thus this positiong contradicts the principles of Uncovered Interest Parity (UIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aac4c9",
   "metadata": {},
   "source": [
    "### 3.2.b) A long position in which foreign currency offered the best Sharpe ratio over the sample?\n",
    "\n",
    "Over the sample, a long position in CHF would have offered positive returns but a low sharpe ratio of ~0.04."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d068a64",
   "metadata": {},
   "source": [
    "### 3.2.c) Are there any foreign currencies for which a long position earned a negative excess return (in USD) over the sample?\n",
    "\n",
    "All currencies except CHF earned a negative excess returns in USD terms. JPY especially had significant negative returns during the sample periods, with increased volatilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4da6a7",
   "metadata": {},
   "source": [
    "### 3.3) Predicting FX\n",
    "\n",
    "For each foreign currency, test whether interest-rate differentials can predict growth in the foreign-exchange rate.1 Do this by estimating the following forecasting regression:\n",
    "\n",
    "#### <center> ${s}^{i}_{t+1} - {s}^{i}_{t} = \\alpha^{i} + \\beta^{i}({r}^{f,$}_{t,t+1} -  {r}^{f,i}_{t,t+1})+\\epsilon_{t+1}$ \n",
    "\n",
    "where  ${r}^{f,i}$ denotes the risk-free rate of currency i, and $s^{i}$ denotes the FX rate for currency i.<br>\n",
    "Again, note that both ${r}^{f,$}_{t,t+1}$ and $s_{t}$ are determined at time t."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423c545",
   "metadata": {},
   "source": [
    "### 3.3.a) Make a table with columns corresponding to a different currency regression. Report the regression estimates $\\alpha^{i}$ and $\\beta^{i}$ in the first two rows. Report the $R^{2}$ stat in the third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e4c0f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBP</th>\n",
       "      <th>EUR</th>\n",
       "      <th>CHF</th>\n",
       "      <th>JPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>-0.005856</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>-0.005976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>5.852952</td>\n",
       "      <td>-15.050115</td>\n",
       "      <td>-19.708839</td>\n",
       "      <td>4.435216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-Squared</th>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.000498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                GBP        EUR        CHF       JPY\n",
       "Alpha     -0.005856   0.007032   0.043548 -0.005976\n",
       "Beta       5.852952 -15.050115 -19.708839  4.435216\n",
       "R-Squared  0.000386   0.002611   0.003947  0.000498"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_hldg_reg = []\n",
    "for k,v in fx_spot_map.items():\n",
    "    factor = risk_free_rates['log_USD1M'].shift(1) - risk_free_rates[k].shift(1)\n",
    "    strat = fx_rates[v] - fx_rates[v].shift(1)\n",
    "    reg = regression_based_performance(factor,strat,0)\n",
    "    beta_currency = reg[0][0]\n",
    "    treynor_ratio = reg[1]\n",
    "    information_ratio = reg[2]\n",
    "    alpha = reg[3]\n",
    "    r_squared = reg[4]\n",
    "    fx_hldg_reg.append(pd.DataFrame([[alpha,beta_currency,r_squared]],columns=['Alpha','Beta','R-Squared'],index = [k[4:7]]))\n",
    "\n",
    "\n",
    "fx_hldg_reg_summary = pd.concat(fx_hldg_reg)\n",
    "fx_hldg_reg_summary = fx_hldg_reg_summary.T\n",
    "fx_hldg_reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6dfab",
   "metadata": {},
   "source": [
    "### 3.3.b) Suppose the foreign risk-free rate increases relative to the US rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ff3b0",
   "metadata": {},
   "source": [
    "### i. For which foreign currencies would we predict a relative strengthening of the USD in the following period?\n",
    "\n",
    "A strengthening U.S. dollar means that it now buys more of the other currency than it did before.If risk-free rate of a currency were to increase relative to the US rate, the currencies with a positive beta in the previous regression would see a decrease in the fx rates (USD per foreign currency). This indicates that there will be a relative strengthening of the USD as a dollar would now buy more of those currencies.\n",
    "\n",
    "From the regression, we see only JPY and GBP having a positive beta and thus would have lower exchange rates in case the risk-free rate of Japan increases. Thus USD would relatively strengthen against JPY and GBP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547426b1",
   "metadata": {},
   "source": [
    "### ii. For which currencies would we predict relative weakening of the USD in the following period?\n",
    "\n",
    "If risk-free rate of a currency were to increase relative to the US rate, the currencies with a negative beta in the previous regression would see an increase in the fx rates (USD per foreign currency). This indicates that there will be a relative weakening of the USD as a dollar would now buy less of those currencies.\n",
    "\n",
    "EUR and CHF both have a negative beta to USD. Thus, USD would experience a relative weakening relative to these 2 currencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211a8b6",
   "metadata": {},
   "source": [
    "### iii. This FX predictability is strongest in the case of which foreign currency?\n",
    "\n",
    "Indicated by the R-Squared in the regression, the FX predictibility seems to be strongest in case of CHF. However, it should be noted that this R-Squared is still fairly low and might not indicate towards a strong enough prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c83fd9",
   "metadata": {},
   "source": [
    "### 3.4) The Dynamic Carry Trade\n",
    "\n",
    "Use this to write $\\mathbb{E}_{t}[\\tilde{r}^{i}_{t+1}]$ as a function of the interest-rate differential as well as $\\alpha$ and $\\beta$ from this FX regression.<br>\n",
    "\n",
    "#### <center> $\\mathbb{E}_{t}[{s}_{t+1} - {s}_{t}] = \\alpha + \\beta({r}^{f,$}_{t,t+1} -  {r}^{f,i}_{t,t+1})$ </center><br>\n",
    "\n",
    "Then use the definition of excess (log) returns on FX:<br>\n",
    "<center> $\\tilde{r}^{i}_{t+1} = {s}_{t+1} - {s}_{t} - ({r}^{f,$}_{t,t+1} -  {r}^{f,i}_{t,t+1})$ </center><br>\n",
    "\n",
    "Rearranging, this implies the following forecast for excess log returns:<br>\n",
    "\n",
    "<center> $\\mathbb{E}_{t}[{s}_{t+1} - {s}_{t}] = \\alpha + (\\beta-1) ({r}^{f,$}_{t,t+1} -  {r}^{f,i}_{t,t+1})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2122b5",
   "metadata": {},
   "source": [
    "### 3.4.a) Use your regression estimates from Problem 3 along with the formula above to calculate the fraction of months for which the estimated FX risk premium positive. That is, for each i, calculate how often in the time-series we have <br>\n",
    "<center>$\\mathbb{E}_{t}[\\tilde{r}^{i}_{t+1}] > 0$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d21681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Months - Positive Premium</th>\n",
       "      <th>Total Months</th>\n",
       "      <th>Frequency(%)-Positive Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBP</th>\n",
       "      <td>13</td>\n",
       "      <td>274</td>\n",
       "      <td>4.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EUR</th>\n",
       "      <td>145</td>\n",
       "      <td>274</td>\n",
       "      <td>52.919708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHF</th>\n",
       "      <td>198</td>\n",
       "      <td>274</td>\n",
       "      <td>72.262774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPY</th>\n",
       "      <td>92</td>\n",
       "      <td>274</td>\n",
       "      <td>33.576642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Months - Positive Premium  Total Months  Frequency(%)-Positive Premium\n",
       "GBP                         13           274                       4.744526\n",
       "EUR                        145           274                      52.919708\n",
       "CHF                        198           274                      72.262774\n",
       "JPY                         92           274                      33.576642"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_prem_lst = []\n",
    "for k,v in fx_spot_map.items():\n",
    "    fx_er_usd = (risk_free_rates['log_USD1M'].shift(1) - risk_free_rates[k].shift(1)).to_frame('ER_over_USD')\n",
    "    expected_fx_premium = float(fx_hldg_reg_summary.loc['Alpha',[k[4:7]]])/12 + (fx_er_usd.loc[:,['ER_over_USD']]  * float(fx_hldg_reg_summary.loc['Beta',[k[4:7]]] - 1))\n",
    "    expected_fx_premium = expected_fx_premium.rename(columns={'ER_over_USD':k[4:7]})\n",
    "    positive_premium =  len(expected_fx_premium[expected_fx_premium[k[4:7]] > 0])\n",
    "    fx_prem_lst.append(pd.DataFrame([[positive_premium,len(expected_fx_premium),positive_premium*100/len(expected_fx_premium)]],columns=['Months - Positive Premium','Total Months','Frequency(%)-Positive Premium'],index=[k[4:7]]))\n",
    "fx_premium = pd.concat(fx_prem_lst)\n",
    "fx_premium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b4c55",
   "metadata": {},
   "source": [
    "### 3.4.b) Which currencies most consistently have a positive FX risk premium? And for which currencies does the FX risk premium most often go negative?\n",
    "\n",
    "GBP displays the highest consistency in producing positive FX risk premium followed by EUR. On the other hand JPY has a negative FX risk premium during all but 5 months in the sample. CHF also has negative premiums ~73% of the months in the sample period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71d853",
   "metadata": {},
   "source": [
    "### 3.4.c) Explain how we could use these conditional risk premia to improve the static carry trade returns calculated in Problem 1.\n",
    "\n",
    "Since from 3.4.a) JPY returns seem to be away from the expected value of 0, an improvement in the carry trade would be to short the JPY i.e. borrow at the JPY risk-free rate to invest in the USD risk-free rate. With our forecast of the USD strengthening relative to the JPY, we could be potentially getting a positive risk premia from this carry trade."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
